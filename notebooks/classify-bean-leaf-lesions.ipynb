{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pytorch library\n",
    "import torch\n",
    "\n",
    "import torch.nn as nn\n",
    "# optim is where we get the stochastic gradient descent optimiser from\n",
    "import torch.optim as optim\n",
    "# transforms perform a set of operations to an individual item (image) so that it is usable by the model\n",
    "import torchvision.transforms as transforms\n",
    "# Tools for creating datasets from folders\n",
    "from torchvision import datasets\n",
    "# default_loader enables basic loading of images to be used in the CustomDataset class\n",
    "from torchvision.datasets.folder import default_loader\n",
    "# DataLoader creates batches of data in a format the model can use\n",
    "# Dataset is a general class that allows the retrieval of individual pieces of data via the DataLoader\n",
    "# All classes that inherit from Dataset must implement the __getitem__ and __len__ \n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics import accuracy, f1_score\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup transform and define CustomDataset class for iterable datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform=transforms.Compose([\n",
    "    transforms.Resize((128, 128)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "])\n",
    "\n",
    "# Use the train.csv and val.csv csv files to create two datasets\n",
    "class CustomDataset(Dataset):\n",
    "    # csv_file is a file path, root_dir is the root of the dataset, transform is an optional instantiation of transforms.Compose\n",
    "    def __init__(self, csv_file, root_dir, transform=None):\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    # How many items are in the dataset\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    # Get a specific item from the dataset by index\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.data.iloc[idx,0] # column 0 contains file paths\n",
    "        img_path = f\"{self.root_dir}/{img_name}\"\n",
    "        # A basic image loader that retruns a Python Imaging Library (PIL) object\n",
    "        image = default_loader(img_path)\n",
    "        label = self.data.iloc[idx,1] # column 1 contains image class\n",
    "\n",
    "        # If there is a transform function, transform the image\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"../datasets/bean-leaf-lesions/\"\n",
    "\n",
    "# CSV file paths\n",
    "train_csv = data_path + 'train.csv'\n",
    "val_csv = data_path + 'val.csv'\n",
    "\n",
    "# Create custom datasets\n",
    "train_dataset = CustomDataset(csv_file=train_csv, root_dir=data_path, transform=transform)\n",
    "val_dataset = CustomDataset(csv_file=val_csv, root_dir=data_path, transform=transform)\n",
    "\n",
    "# Create Dataloaders\n",
    "batch_size=32\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_data_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train batches: 33\n",
      "Val batches: 5\n"
     ]
    }
   ],
   "source": [
    "# print how many batches are in the train and val dataloaders\n",
    "print(f\"Train batches: {len(train_dataloader)}\")\n",
    "print(f\"Val batches: {len(val_data_loader)}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nn.Module is the base class for all NN modules in pytorch\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        # CNN class inherits from nn.Module\n",
    "        # Inheriting allows the use of functions from the parent class\n",
    "        super(CNN, self).__init__()\n",
    "        # Input = RGB, Output = number of filters/kernels in the layer, \n",
    "        # kernel_size = height&width of convolutional window, padding = number of 0 pixels added to edge of image\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels= 16, kernel_size= 3, padding=1)\n",
    "        # kernel_size = size of the max pooling window\n",
    "        # step_size determines how much the kernel moves by after each pooling operation\n",
    "        # With both of these being 2, the spatial dimension is halved\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        # The number of outputs increases with the depth of the model because the complexity of the\n",
    "        # learned representations requires more neurons\n",
    "        self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, padding=1)\n",
    "        # 32 is the previous layers output size, and 8 is the size of the image after the pooling layer\n",
    "        # so 32 * 8 * 8 is the number of dimensions in the flattened tensor\n",
    "        self.fc1 = nn.Linear(32 * 32 * 32, 128)\n",
    "        self.fc2 = nn.Linear(128, 3) # 3 possible classes in the dataset\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Apply conv1 to the input, apply relu activation, apply max pooling\n",
    "        x = self.pool(torch.relu(self.conv1(x)))\n",
    "        x = self.pool(torch.relu(self.conv2(x)))\n",
    "        # x.view is a pytorch fn used to reshape tensors\n",
    "        # This flattens the tensor into a 1D vector of 32*8*8 elements\n",
    "        # The -1 is a placeholder to allow pytorch to automatically compute the size of that dimension\n",
    "        # The total number of elements in the tensor is used (e.g. tensor contains 100 elems, x.view(5, -1) would resolve -1 to 20)\n",
    "        x = x.view(-1, 32 * 32 * 32)\n",
    "        # Puth the flattened tensor through a fully connected layer\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        # Resolve to one of the 3 possible classes\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "model = CNN()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define loss function and optimiser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss() # Computes softmax as well as loss\n",
    "\n",
    "# Momentum at 0.9 means that the gradient will be 90% influenced by previous gradients and 10% by the current\n",
    "# Allows for faster convergence by moving more in steeper situations and less in shallow\n",
    "optimiser = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss 1.0881008957371567\n",
      "Epoch 2, Loss 1.04708270593123\n",
      "Epoch 3, Loss 0.96774218118552\n",
      "Epoch 4, Loss 0.8893889206828494\n",
      "Epoch 5, Loss 0.8263057813499913\n"
     ]
    }
   ],
   "source": [
    "num_epochs=5\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss=0.0\n",
    "    # Generates tuples containing index 'i' and elements 'data'\n",
    "    # the 0 argument sets the index to begin at 0\n",
    "    # the index refers to which batch of data we are currently looking at\n",
    "    # the data refers to the collection of data points in that batch, with inputs and labels\n",
    "    for i, data in enumerate(train_dataloader, 0):\n",
    "        inputs, labels = data\n",
    "\n",
    "        # clears any previously generated gradients\n",
    "        # For each data point, we n\n",
    "        optimiser.zero_grad()\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        # computes gradients of the loss wrt model params with back-prop\n",
    "        loss.backward()\n",
    "        # Updates model parameters using gradients from loss.backward(), which stored the gradients within the model params\n",
    "        # Since the model params are stored in the optimiser anyway, we do no need to explicitly handle this arg\n",
    "        optimiser.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        # if i % 1000 == 999: # Print every 1k mini batches\n",
    "        #     print(f'Epoch {epoch+1}, Mini batch {i+1}, Loss {running_loss/1000}')\n",
    "        #     running_loss = 0.0\n",
    "    # Print the loss after each epoch\n",
    "    print(f'Epoch {epoch+1}, Loss {running_loss/len(train_dataloader)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0ffb79dba2b0659ac21bde8e88d8bd6113f5558632155a003a95479e7df48b66"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
